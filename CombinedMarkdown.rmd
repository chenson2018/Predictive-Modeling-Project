---
title: "CombinedMarkdown"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}    
library(dplyr)
library(tidyr)
library(ggplot2)
library(Amelia)

#Read in files
g_data <- read.csv("general_data.csv")
ms_data <- read.csv("manager_survey_data.csv")
es_data <- read.csv("employee_survey_data.csv")
in_time <- read.csv("in_time.csv")
out_time <- read.csv("out_time.csv")
hours <- read.csv("Employee_Daily_Hours_Final.csv")
names(hours)[1] <- "EmployeeID"
```

```{r}
Master_Data <- merge(g_data,es_data,by = 'EmployeeID',all = F)
Master_Data <- merge(Master_Data,ms_data,by = 'EmployeeID',all = F)
Master_Data <- merge(Master_Data,hours,by = 'EmployeeID',all = F)

##MISSING DATA
#Omit NA data from dataframe since very little NA
Master_Data <- na.omit(Master_Data)
#No more missing values
```


```{r}
##CLEAN DATA

#Remove columns we dont need in our analysis
#Master_Data <- select(Master_Data,-EmployeeID,-EmployeeCount,-Over18,-StandardHours)
Master_Data$StandardHours <- NULL
Master_Data$Over18 <- NULL
Master_Data$EmployeeCount <- NULL
Master_Data$EmployeeID <- NULL
```


```{r}
##SPLIT DATA
library(caTools)

sample <- sample.split(Master_Data$Attrition,SplitRatio = 0.7)

#Training Data
train <- subset(Master_Data,sample==T)
#Testing Data
test <- subset(Master_Data,sample==F)
```

```{r}
##TRAIN THE LOGISTIC REGRESSION MODEL
logModel <- glm(Attrition ~., family = binomial('logit'),data = train)
summary(logModel)
```

```{r}
##PREDICTIONS
pred_probabilities <- predict(logModel,test,type = 'response')
pred_results <- ifelse(pred_probabilities>0.5,1,0)

#Convert Attrition column in test to 0s and 1s to compare to pred_results
test$AttritionClass <- ifelse(test$Attrition == 'Yes',1,0)

misClassError <- mean(pred_results != test$AttritionClass)
accuracy <- (1-misClassError)

cat("Misclassification error:", misClassError, "\n")
cat("Accuracy:", accuracy, "\n")
```

```{r}
#error types
match <- data.frame(cbind(pred_results, reg_results = test$AttritionClass))

match$error[(match$pred_results == 1 & match$reg_results ==1)] <- 'True positive'
match$error[(match$pred_results == 0 & match$reg_results ==1)] <- 'False negative'
match$error[(match$pred_results == 0 & match$reg_results ==0)] <- 'True negative'
match$error[(match$pred_results == 1 & match$reg_results ==0)] <- 'False positive'

errorType <- as.data.frame(addmargins(table(match$error)))

print(errorType)

cat("Probability that an employee predicted to stay leaves:", errorType[1, 2]/(errorType[1, 2] + errorType[3, 2]))
cat("\nProbability that an employee predicted to leave stays:", errorType[2, 2]/(errorType[2, 2] + errorType[4, 2]))
```

```{r}
#LASSO to determine variables to include
library(glmnet)
trainMatrix <- model.matrix(Attrition ~ ., data = train)
testMatrix <- model.matrix(Attrition ~ ., data = test)
grid <- 10 ^ seq(4, -2, length = 100)
lasso <- glmnet(trainMatrix, train$Attrition, alpha = 1, lambda = grid, thresh = 1e-12, family = "binomial")
lassoCV <- cv.glmnet(trainMatrix, train$Attrition, alpha = 1, lambda = grid, thresh = 1e-12, family = "binomial")
lassoLambdaMin <- lassoCV$lambda.min
predict(lasso, s = lassoLambdaMin, type = "coefficients")
```

```{r}
plot(lasso, xvar = "dev")
plot(lasso, xvar = "lambda")
plot(lasso, xvar = "norm")
```

```{r}
#new Logistic model
logModel2 <- glm(Attrition ~ Age + BusinessTravel + JobRole + MaritalStatus + NumCompaniesWorked + StockOptionLevel + TotalWorkingYears + TrainingTimesLastYear + YearsSinceLastPromotion + YearsWithCurrManager + EnvironmentSatisfaction + JobSatisfaction + WorkLifeBalance, family = binomial('logit'),data = train)

summary(logModel2)
```

```{r}
pred_probabilities2 <- predict(logModel2,test,type = 'response')
pred_results2 <- ifelse(pred_probabilities2>0.5,1,0)

#Convert Attrition column in test to 0s and 1s to compare to pred_results
test$AttritionClass <- ifelse(test$Attrition == 'Yes',1,0)

misClassError2 <- mean(pred_results2 != test$AttritionClass)
accuracy2 <- (1-misClassError2)

cat("Misclassification error:", misClassError2, "\n")
cat("Accuracy:", accuracy2, "\n")
```

```{r}
#error types for new logisitc regression
match <- data.frame(cbind(pred_results2, reg_results = test$AttritionClass))

match$error[(match$pred_results == 1 & match$reg_results ==1)] <- 'True positive'
match$error[(match$pred_results == 0 & match$reg_results ==1)] <- 'False negative'
match$error[(match$pred_results == 0 & match$reg_results ==0)] <- 'True negative'
match$error[(match$pred_results == 1 & match$reg_results ==0)] <- 'False positive'

errorType <- as.data.frame(addmargins(table(match$error)))

print(errorType)

cat("Probability that an employee predicted to stay leaves:", errorType[1, 2]/(errorType[1, 2] + errorType[3, 2]))
cat("\nProbability that an employee predicted to leave stays:", errorType[2, 2]/(errorType[2, 2] + errorType[4, 2]))
```

```{r}
library(randomForest)
set.seed(1)

finrf = randomForest(Attrition~.,data=train,ntree=500)
finrfpred=predict(finrf,newdata=test)


cat("Misclassification error:", sum(abs(as.numeric(test$Attrition)-as.numeric(finrfpred)))/nrow(test))

finrfrmse = sqrt(sum((as.numeric(test$Attrition)-as.numeric(finrfpred))^2)/nrow(test))

varImpPlot(finrf)
```
